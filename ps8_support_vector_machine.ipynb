{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi2mycFYo9ch3SYdAyjYnY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenx1/learning-systems/blob/main/ps8_support_vector_machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HEQaMMGORri",
        "outputId": "378ea174-39a6-4169-a3c9-e2673f043784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "import random\n",
        "import math\n",
        "from typing import List\n",
        "from itertools import product\n",
        "import scipy.special\n",
        "from scipy import optimize\n",
        "import scipy.optimize as spo\n",
        "from sympy import Symbol, Derivative\n",
        "import functools\n",
        "from sklearn import svm, model_selection\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, RepeatedKFold\n",
        "\n",
        "\n",
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data\n",
        "train = np.loadtxt('/content/drive/MyDrive/features.train')\n",
        "test = np.loadtxt('/content/drive/MyDrive/features.test')\n",
        "\n",
        "X_train = train[:,1:]\n",
        "Y_train = train[:,0]\n",
        "N_train = X_train[:, 0].size\n",
        "\n",
        "X_test = test[:,1:]\n",
        "Y_test = test[:,0]\n",
        "N_test = X_test[:, 0].size"
      ],
      "metadata": {
        "id": "HqRpx9MQO5IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = .01\n",
        "Q = 2"
      ],
      "metadata": {
        "id": "uTrniW9xPRHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_binary(Y, classes):\n",
        "    return np.array([1 if y == classes else -1 for y in Y])\n",
        "\n",
        "def score(y_class):\n",
        "    # Set all other labels to 0 to make it a binary y_class vs all classification\n",
        "    bin_Y_train = to_binary(Y_train, y_class)\n",
        "    bin_Y_test = to_binary(Y_test, y_class)\n",
        "\n",
        "    clf = svm.SVC(kernel='poly', C=C, degree=Q, gamma=1.0, coef0=1.0, cache_size=20000)\n",
        "    clf.fit(X_train, bin_Y_train)\n",
        "    print(f\"Score of {y_class} versus all = {clf.score(X_test, bin_Y_test)}\")"
      ],
      "metadata": {
        "id": "ORGGNDBbQCVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  score(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Y6roKbQLFq",
        "outputId": "4b3c91fd-2701-460d-fcf4-4128ca97c589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score of 0 versus all = 0.8883906327852517\n",
            "Score of 1 versus all = 0.9780767314399601\n",
            "Score of 2 versus all = 0.9013452914798207\n",
            "Score of 3 versus all = 0.9172894867962132\n",
            "Score of 4 versus all = 0.9003487792725461\n",
            "Score of 5 versus all = 0.9202790234180369\n",
            "Score of 6 versus all = 0.9152964623816642\n",
            "Score of 7 versus all = 0.9267563527653214\n",
            "Score of 8 versus all = 0.9172894867962132\n",
            "Score of 9 versus all = 0.9118086696562033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_support_vectors(y_class):\n",
        "    # Set all other labels to 0 to make it a binary y_class vs all classification\n",
        "    bin_Y_train = to_binary(Y_train, y_class)\n",
        "    bin_Y_test = to_binary(Y_test, y_class)\n",
        "\n",
        "    clf = svm.SVC(kernel='poly', C=C, degree=Q, gamma=1.0, coef0=1.0, cache_size=20000)\n",
        "    clf.fit(X_train, bin_Y_train)\n",
        "    return sum(clf.n_support_)"
      ],
      "metadata": {
        "id": "RmuTBqkuQsZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_support_vectors(0) - num_support_vectors(1)"
      ],
      "metadata": {
        "id": "jDf7L3cIQ0cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_svm_tuning(X_train, Y_train, X_test, Y_test, q_value=2, num_runs=100, C_values=[.0001, .001, .01, .1, 1]):\n",
        "    results = []\n",
        "    cross_val_errors = []\n",
        "\n",
        "    def get_binary_data(data, first_class, second_class):\n",
        "        X, Y = data\n",
        "        indices = (Y == first_class) | (Y == second_class)\n",
        "        return X[indices], Y[indices]\n",
        "\n",
        "    X_test_1vs5, Y_test_1vs5 = get_binary_data((X_test, Y_test), 1, 5)\n",
        "    X_train_1vs5, Y_train_1vs5 = get_binary_data((X_train, Y_train), 1, 5)\n",
        "\n",
        "    for _ in range(num_runs):\n",
        "        for train_idx, val_idx in zip(range(0, len(X_train_1vs5), len(X_train_1vs5)//10),\n",
        "                                      range(len(X_train_1vs5)//10, len(X_train_1vs5)+1, len(X_train_1vs5)//10)):\n",
        "            X_train_subset, X_val = X_train_1vs5[:train_idx] + X_train_1vs5[val_idx:], X_train_1vs5[train_idx:val_idx]\n",
        "            Y_train_subset, Y_val = Y_train_1vs5[:train_idx] + Y_train_1vs5[val_idx:], Y_train_1vs5[train_idx:val_idx]\n",
        "\n",
        "            top_score = 0\n",
        "            best_parameters = None\n",
        "            for C_value in C_values:\n",
        "                for q_value in range(q_value):  # Changed variable name from Qs to q_value\n",
        "                    clf = svm.SVC(kernel='poly', C=C_value, degree=q_value, gamma=1.0, coef0=1.0, cache_size=20000)\n",
        "                    clf.fit(X_train_subset, Y_train_subset)\n",
        "                    current_score = clf.score(X_val, Y_val)\n",
        "                    if current_score > top_score:\n",
        "                        top_score = current_score\n",
        "                        best_parameters = (C_value, q_value)\n",
        "\n",
        "            results.append(best_parameters)\n",
        "            clf = svm.SVC(kernel='poly', C=best_parameters[0], degree=best_parameters[1], gamma=1.0, coef0=1.0, cache_size=20000)\n",
        "            clf.fit(X_train_subset, Y_train_subset)\n",
        "            cross_val_errors.append(1 - clf.score(X_val, Y_val))\n",
        "\n",
        "    unique_parameters, counts = np.unique(results, return_counts=True, axis=0).T\n",
        "    print(\"Unique Parameters: \", unique_parameters)\n",
        "    print(\"Counts: \", counts)\n",
        "    average_error = np.mean(cross_val_errors)\n",
        "    print(\"Average Cross-Validation Error: \", average_error)"
      ],
      "metadata": {
        "id": "eFsxbmNsmjaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary_data(data, first_class, second_class):\n",
        "        X, Y = data\n",
        "        indices = (Y == first_class) | (Y == second_class)\n",
        "        return X[indices], Y[indices]\n",
        "\n",
        "Cs = [0.01, 1, 100, 1e4, 1e6]\n",
        "\n",
        "X_test_new,Y_test_new = get_binary_data((X_test, Y_test), 1, 5)\n",
        "X_train_new, Y_train_new = get_binary_data((X_train, Y_train), 1, 5)\n",
        "\n",
        "def compute_eIN(C):\n",
        "    clf = svm.SVC(kernel='rbf', C=C, degree=Q, gamma=1.0, cache_size=20000)\n",
        "    clf.fit(X_train_new, Y_train_new)\n",
        "    return 1 - clf.score(X_train_new, Y_train_new)\n",
        "\n",
        "print([compute_eIN(C) for C in Cs])"
      ],
      "metadata": {
        "id": "OVbMugG3t0Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_eOUT(C):\n",
        "    clf = svm.SVC(kernel='rbf', C=C, degree=Q, gamma=1.0, cache_size=20000)\n",
        "    clf.fit(X_train_new, Y_train_new)\n",
        "    return 1 - clf.score(X_test_new, Y_test_new)\n",
        "\n",
        "print([compute_eOUT(C) for C in Cs])"
      ],
      "metadata": {
        "id": "-LAsgEB0uYQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}